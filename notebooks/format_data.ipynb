{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "from astropy import units as u\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib import rc\n",
    "plt.style.use('classic')\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "rc('text', usetex=True)\n",
    "rc('figure', facecolor='w')\n",
    "rc('xtick', labelsize=20)\n",
    "rc('ytick', labelsize=20)\n",
    "\n",
    "from dtaidistance import dtw, clustering\n",
    "from dtaidistance import dtw_visualisation as dtwvis\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "sys.path.append('/astro/users/jbirky/projects/tess_binaries')\n",
    "os.environ['TESS_DATA'] = '/data/epyc/projects2/tess'\n",
    "\n",
    "import tess_binaries as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_xm = pd.read_csv(tb.cat_dir + '/asassn_tess_xm.csv.gz')\n",
    "psamp = tess_xm[~np.isnan(tess_xm['period'])]\n",
    "ref = psamp[psamp['period'] < 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = np.array([368, 212, 276, 275, 483, 1103, 381, 1105, 957, 127, 1116, 13, 961, 1054, 840, 544, 136, 596, 17, 1122, 19, 231, 752, 967, 969, 1127, 547, 1142, 549, 554, 603, \\\n",
    "           1154, 759, 662, 605, 413, 32, 856, 860, 861, 977, 766, 317, 1192, 984, 563, 869, 609, 680, 162, 47, 872, 990, 171, 684, 173, 11209, 1213, 1215, 512, 175, 514, \\\n",
    "           1071, 997, 262, 441, 1002, 777, 78, 1003, 79, 520, 180, 778, 701, 444, 1011, 1015, 780, 709, 712, 190, 191, 714, 577, 784, 345, 902, 905, 529, 908, 1269, 1080, \\\n",
    "           618, 619, 1018, 348, 1270, 1272, 622, 1274, 1277, 716, 792, 349, 578, 1028, 1090, 794, 626, 450, 1091, 923, 534, 628, 799, 802, 805, 806, 807, 808, 110, 934, 937, \\\n",
    "           1299, 581, 942, 943, 539, 814, 949, 952, 1047, 1050, 737, 479, 1051, 0, 285, 8, 845, 749, 141, 655, 756, 501, 604, 857, 665, 562, 65, 775, 440, 1242, 613, 81, \\\n",
    "           1267, 616, 353, 922, 533, 451, 1296, 936, 1040, 939, 118, 582, 473, 561, 657, 999, 1073, 1244, 516, 178, 1007, 1265, 1016, 1075, 1019, 198, 1021, 1023, 1037, 1039, \\\n",
    "           580, 119, 1044, 1045, 480, 747, 966, 652, 1132, 560, 868, 1234 , 572, 614, 87, 267, 1087, 1026, 1032, 200, 816, 821, 53,   88,  140,  189,  243,  321,  435,  542,  \\\n",
    "           566,  588,  825, 1049, 1066, 1094, 1172, 1199, 18,  223,  552,  647,  675,  919, 944, 73])\n",
    "good_ids = np.array(list(set(np.arange(0,len(ref))) - set(bad_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_per = np.array([229807000, 302965929,  80427866, 311086887, 165124012, 179050471,\n",
    "       245865916,  27629711, 178547903,  25669623, 465075473, 462146751,\n",
    "       129181676, 411956826, 159454564, 193565852, 91369561, 54018297, 131793466, 47380518, 169249901, 359830202, 437091565,\n",
    "      270038761])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  53,   88,  140,  189,  243,  321,  435,  542,  566,  588,  825,\n",
       "       1049, 1066, 1094, 1172, 1199,   18,  223,  552,  647,  675,  919,\n",
       "        944,   73])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.where(ref['tic_id'] == b)[0][0] for b in bad_per])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'tic_id':[], 'type':[], 'period':[], 'sector':[]}\n",
    "for i in good_ids:\n",
    "    df['tic_id'].append(list(ref['tic_id'])[i])\n",
    "    df['type'].append(list(ref['Type'])[i])\n",
    "    df['period'].append(list(ref['period'])[i])\n",
    "    df['sector'].append(list(ref['sector'])[i])\n",
    "train = pd.DataFrame(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsteps = 100\n",
    "tarr = np.arange(0,tsteps,1)\n",
    "pharr = np.linspace(0,1,tsteps)\n",
    "\n",
    "table = train\n",
    "# demo = random.choices(np.arange(0,len(train)), k=N)\n",
    "sample = {'tic_id':[], 'type':[], 'period':[], 'flux':[]}\n",
    "\n",
    "for i in range(len(table)):\n",
    "    try:\n",
    "        data_full = tb.readSourceFiles(table['tic_id'][i], sector=table['sector'][i])[0]     \n",
    "        data      = data_full.fold(period=table['period'][i]*u.day) \n",
    "        bin_flux  = tb.binData(data, tsteps)\n",
    "\n",
    "        flux = np.roll(np.array(bin_flux), tsteps-np.argmin(bin_flux))\n",
    "\n",
    "        data = np.vstack([tarr, flux]).T\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(data)\n",
    "        flux = scaler.transform(data).T[1]\n",
    "\n",
    "        sample['flux'].append(flux)\n",
    "        sample['tic_id'].append(table['tic_id'][i])\n",
    "        sample['period'].append(table['period'][i])\n",
    "        sample['type'].append(table['type'][i])\n",
    "    except:\n",
    "        print('BAD ID', i, table['tic_id'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=sample)\n",
    "fname = f'{tb.cat_dir}/asassn_tess_inspected.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(fname, 'w') as f:\n",
    "    f.create_dataset('tic_id', data=df['tic_id'])\n",
    "    f.create_dataset('period', data=df['period'])\n",
    "    f.create_dataset('type', data=df['type'], dtype=h5py.special_dtype(vlen=str))\n",
    "    f.create_dataset('flux', data=df['flux'], dtype=h5py.special_dtype(vlen=np.dtype('float64')))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = h5py.File(f'{tb.cat_dir}/asassn_tess_inspected.hdf5', mode=\"r\")\n",
    "\n",
    "dd = {}\n",
    "for key in list(ff):\n",
    "    dd[key] = ff[key].value\n",
    "    \n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1004"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = np.array(['91369561','152223725','270038761','340219000','41865879','308451526','41865879','306736831','314826925','54018297','452357628','31281820','170882537','219203188','50745582','102202982','110793065','131793466','265206385','47380518','169249901','188209486','29850366','359830202','396004353','437091565','41169654','67271271','229807000','302965929','311086887','144598282','179050471','245865916','27629711','178547903','25669623','465075473','462146751','129181676','411956826','159454564','193565852'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample[~sample['tic_id'].isin(bad_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/epyc/opt/anaconda/lib/python3.6/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "ff = h5py.File(f'{tb.cat_dir}/asassn_tess_inspected_0.hdf5', mode=\"r\")\n",
    "\n",
    "df = {}\n",
    "for key in list(ff):\n",
    "    if key == 'type':\n",
    "        df[key] = np.array(ff[key].value, dtype='str')\n",
    "    else:\n",
    "        df[key] = ff[key].value\n",
    "    \n",
    "ff.close()\n",
    "sample = pd.DataFrame(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
